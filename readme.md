# üçΩÔ∏è Assistant Culinaire & Calories IA
![image](https://github.com/user-attachments/assets/31df8e83-47af-43ab-b9b2-39f614b6a3b2)
![image](https://github.com/user-attachments/assets/97a11e72-3cc0-4ad4-9a33-a7f7d6563347)


[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Ollama-Required-green.svg)](https://ollama.ai/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-3.0.0-red.svg)]((https://github.com/nourhene196/ollama2025))

> **Application moderne de g√©n√©ration de recettes et calcul de calories utilisant l'IA llama3.2:1b via Ollama**

Une application Python avec interface graphique qui combine la g√©n√©ration intelligente de recettes et l'analyse nutritionnelle approfondie, aliment√©e par le mod√®le d'IA llama3.2:1b.

## ‚ú® Fonctionnalit√©s

G√©n√©ration de Recettes IA
- S√©lection intuitive d'ingr√©dients avec interface moderne
- Options de personnalisation (cuisine, difficult√©, temps)
- G√©n√©ration 100% IA avec llama3.2:1b (1.3GB)
- Recettes fran√ßaises cr√©atives et d√©taill√©es
- Export des recettes en format TXT

 Calculateur de Calories IA
- Base de donn√©es nutritionnelle int√©gr√©e (25+ aliments)
- Calcul pr√©cis des calories et macronutriments
- Analyse nutritionnelle approfondie par IA
- Conseils sant√© personnalis√©s par llama3.2:1b
- Export des analyses en format CSV

Interface Moderne
- Design moderne avec onglets s√©par√©s
- Interface intuitive et r√©active
- Feedback visuel temps r√©el
- Messages d'aide int√©gr√©s
- Diagnostic automatique des probl√®mes

## üöÄ Installation

### Pr√©requis

- **Python 3.7+** ([T√©l√©charger](https://www.python.org/downloads/))
- **Ollama** ([T√©l√©charger](https://ollama.ai/download))
- **Connexion Internet** (pour t√©l√©charger le mod√®le)

### √âtape 1: Cloner le projet

```bash    

git clone https://github.com/nourhene196/ollama2025.git
cd assistant-culinaire-ia
```

### √âtape 2: Installer les d√©pendances Python

```bash
# Installer les modules requis
pip install requests pandas

# V√©rifier l'installation
python --version  # Doit √™tre 3.7+
```

### √âtape 3: Installer et configurer Ollama

#### Windows
1. T√©l√©chargez depuis [ollama.ai/download/windows](https://ollama.ai/download/windows)
2. Installez le fichier `.exe`
3. Red√©marrez votre ordinateur

#### macOS
1. T√©l√©chargez depuis [ollama.ai/download/mac](https://ollama.ai/download/mac)
2. Installez le fichier `.dmg`

#### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### √âtape 4: D√©marrer Ollama

```bash
# Dans un terminal (gardez-le ouvert)
ollama serve
```

Vous devriez voir : `Ollama is running on http://localhost:11434`

### √âtape 5: Installer le mod√®le llama3.2:1b

```bash
# Dans un NOUVEAU terminal
ollama pull llama3.2:1b
```

‚è≥ **T√©l√©chargement :** ~1.3GB, patientez quelques minutes selon votre connexion.

### √âtape 6: V√©rifier l'installation

```bash
# Lister les mod√®les install√©s
ollama list

# Tester le mod√®le
ollama run llama3.2:1b "Bonjour, peux-tu cr√©er une recette fran√ßaise ?"
```

## üéØ Utilisation

### Lancement de l'application

```bash
# Assurez-vous qu'Ollama tourne (ollama serve)
python main.py
```

### Interface

L'application s'ouvre avec 3 onglets :

#### üçΩÔ∏è **G√©n√©rateur de Recettes**
1. **S√©lectionnez vos ingr√©dients** dans la liste √† gauche
2. **Choisissez vos options** (cuisine, difficult√©, temps)
3. **Cliquez sur "G√âN√âRER AVEC llama3.2:1b"**
4. **Consultez votre recette** fran√ßaise personnalis√©e
5. **Exportez** si souhait√©

#### üìä **Calculateur de Calories**
1. **Ajoutez vos aliments** avec leurs quantit√©s
2. **Visualisez les totaux** nutritionnels en temps r√©el
3. **Cliquez sur "ANALYSER AVEC IA"** pour l'analyse approfondie
4. **Consultez les conseils** sant√© de llama3.2:1b
5. **Exportez en CSV** si souhait√©

#### ü§ñ **Statut IA**
1. **V√©rifiez l'√©tat** d'Ollama et llama3.2:1b
2. **Testez la g√©n√©ration** IA
3. **Consultez les instructions** de d√©pannage

## üìÅ Structure du Projet

```
assistant-culinaire-ia/
‚îú‚îÄ‚îÄ config.py              # Configuration de l'application
‚îú‚îÄ‚îÄ models.py               # Mod√®les de donn√©es et gestionnaire
‚îú‚îÄ‚îÄ ollama_service.py       # Service de communication Ollama
‚îú‚îÄ‚îÄ recipe_service.py       # Service de g√©n√©ration de recettes
‚îú‚îÄ‚îÄ calorie_service.py      # Service de calcul de calories
‚îú‚îÄ‚îÄ main.py                 # Application principale
‚îú‚îÄ‚îÄ README.md               # Documentation
‚îú‚îÄ‚îÄ LICENSE                 # Licence MIT
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îú‚îÄ‚îÄ .gitignore             # Fichiers √† ignorer
‚îî‚îÄ‚îÄ data/                  # Donn√©es (cr√©√© automatiquement)
    ‚îî‚îÄ‚îÄ calories.csv       # Base nutritionnelle
```

## ‚öôÔ∏è Configuration

### Param√®tres par d√©faut

```python
# Dans config.py
OLLAMA_MODEL = "llama3.2:1b"    # Mod√®le IA utilis√©
OLLAMA_BASE_URL = "http://localhost:11434"  # URL Ollama
APP_GEOMETRY = "1600x1000"      # Taille de fen√™tre
```

### Base de donn√©es nutritionnelle

L'application inclut une base de donn√©es de 25+ aliments avec :
- Calories par 100g
- Prot√©ines, glucides, lipides
- Fibres et cat√©gories
- Extensible via CSV

## üõ†Ô∏è D√©pannage

### Probl√®mes courants

#### ‚ùå "Ollama n'est pas disponible"
```bash
# Solution 1: D√©marrer Ollama
ollama serve

# Solution 2: V√©rifier le port
curl http://localhost:11434/api/tags

# Solution 3: Red√©marrer proprement
pkill ollama  # Linux/Mac
taskkill /F /IM ollama.exe  # Windows
ollama serve
```

#### ‚ùå "llama3.2:1b n'est pas disponible"
```bash
# Installer le mod√®le
ollama pull llama3.2:1b

# V√©rifier l'installation
ollama list
```

#### ‚ùå "Module 'requests' not found"
```bash
# Installer les d√©pendances
pip install requests pandas
```

#### ‚ùå Erreurs de timeout
```bash
# Red√©marrer Ollama et l'application
ollama serve
python main.py
```

### Mode diagnostic

```bash
# Test complet de l'installation
python main.py --help

# Test manuel du mod√®le
ollama run llama3.2:1b "test"
```

## üîß D√©veloppement

### Pr√©requis d√©veloppement

```bash
pip install requests pandas tkinter
```

### Architecture

L'application suit une architecture modulaire :

- **`config.py`** : Configuration centralis√©e
- **`models.py`** : Mod√®les de donn√©es (Ingredient, Recipe, etc.)
- **`ollama_service.py`** : Abstraction de l'API Ollama
- **`recipe_service.py`** : Logique de g√©n√©ration de recettes
- **`calorie_service.py`** : Logique de calcul nutritionnel
- **`main.py`** : Interface graphique et orchestration

### Ajout d'aliments

Pour ajouter des aliments √† la base de donn√©es :

1. Modifiez `_create_sample_data()` dans `models.py`
2. Ou cr√©ez un fichier `data/calories.csv` avec les colonnes :
   ```
   name,calories,protein,carbs,fat,fiber,category
   ```

### Personnalisation des prompts

Modifiez les prompts IA dans `config.py` :

```python
PROMPTS = {
    'recipe_system': "Tu es un chef cuisinier...",
    'recipe_prompt': "Cr√©e une recette avec...",
    # ...
}
```

## üìà Performances

### Ressources syst√®me

- **RAM** : ~200MB en fonctionnement
- **Espace disque** : ~1.5GB (mod√®le llama3.2:1b)
- **CPU** : Mod√©r√© pendant la g√©n√©ration IA
- **R√©seau** : Uniquement pour t√©l√©charger le mod√®le

### Temps de r√©ponse

- **G√©n√©ration de recette** : 5-15 secondes
- **Analyse nutritionnelle** : 3-10 secondes
- **Calculs de base** : Instantan√©

## ü§ù Contribution

Les contributions sont les bienvenues ! 

### Comment contribuer

1. **Fork** le projet
2. **Cr√©ez** une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. **Commitez** vos changements (`git commit -m 'Ajouter nouvelle fonctionnalit√©'`)
4. **Pushez** vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. **Ouvrez** une Pull Request

### Id√©es de contributions

- üåç Support d'autres langues
- ü•ò Nouvelles cuisines et styles
- üìä Graphiques nutritionnels
- üîÑ Autres mod√®les IA (Mistral, etc.)
- üì± Interface mobile
- üóÑÔ∏è Base de donn√©es √©tendue

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üë• Auteurs

- **Votre Nom** - *D√©veloppement initial* - [VotreGitHub](https://github.com/votre-username)

## üôè Remerciements

- **Ollama** pour l'infrastructure IA locale
- **Meta** pour le mod√®le Llama 3.2
- **Communaut√© Python** pour les outils et biblioth√®ques
- **Contributors** pour les am√©liorations et suggestions

## üìû Support

- **Issues GitHub** : [Signaler un probl√®me][(https://github.com/nourhene196/ollama2025))
- **Documentation** : Ce README et commentaires dans le code
- **Ollama Support** : [ollama.ai](https://ollama.ai/)

## üîó Liens Utiles

- [Documentation Ollama](https://github.com/ollama/ollama)
- [Mod√®le Llama 3.2](https://ollama.ai/library/llama3.2)
- [Python Tkinter](https://docs.python.org/3/library/tkinter.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

---

‚≠ê **N'oubliez pas de donner une √©toile au projet si vous l'appr√©ciez !** ‚≠ê
